<!DOCTYPE html>
<html lang="en">
  <head>

    <meta charset="utf-8" />
    <title>William Lachance's Log (page 11)</title>
    <meta name="description" content="William Lachance's Log (page 11)" />
    <meta name="author" content="William Lachance" />
    <meta name="keywords" content="Orangutan, Meditation, Iodide, Web, GoFaster, Release Engineering, zen, Python, Glean, Time, Metrics Graphics, iphone, Buddhism, Video, Transit to Go, Responsiveness, Data, Profiling, Docker, Social Media, GNOME, Psychology, Personal, Food, Montreal, Taskcluster, Talos, Telemetry, Treeherder, Mozilla, telemetry, Open Data, ateam, Data Visualization, mozregression, all, MSF, Pandaboard, Polling, Philosophy, Recurse, Usability, Meta, Irydium, Counting, email, Infraherder, Statistics, Free Software, Bikes, Mission Control, Nixi, Music, Business, Transit, BIXI, iodide, AI, Life, ÃŽle Sans Fil, Eideticker, Android, Voltus, Performance, FirefoxOS, hbus, Documentation, Environment, meta, Toronto, Ebola, Cats, Perfherder, Coffee, WifiDog, Sphinx, SQL, Community" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" href="/favicon.ico" />
    <link rel="canonical" href="https://wrla.ch/index-11.html" />

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="/css/style.css" />
    <link
      rel="stylesheet"
      type="text/css"
      href="/css/pygments.css"
    />
    <link
      rel="stylesheet"
      type="text/css"
      href="/css/scribble.css"
    />
    <!-- Feeds -->
    <link
      rel="alternate"
      type="application/atom+xml"
      href="/feeds/all.atom.xml"
      title="Atom Feed"
    />
    <link
      rel="alternate"
      type="application/rss+xml"
      href="/feeds/all.rss.xml"
      title="RSS Feed"
    />
    <!-- JS -->
    <script type="text/javascript">
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-xxxxx', 'auto');
      ga('send', 'pageview');
    </script>
  </head>
  <body>
    <nav
      class="flex items-center justify-between flex-wrap bg-gray-800 py-1 px-8"
    >
      <div class="flex items-center flex-shrink-0 text-gray-400 mr-6">
        <div class="p-1">
          <a href="/index.html"
            ><img
              src="/img/wlach_icon.png"
              width="32"
              height="32"
              class="p rounded"
          /></a>
        </div>
        <div class="p-1">
          <a
            href="/index.html"
            class="text-gray-200 font-semibold text-xl tracking-tight hover:text-white"
            >wlach log</a
          >
        </div>
      </div>
      <div class="flex-grow lg:flex lg:items-center">
        <div class="text-sm lg:flex-grow">
          <a
            href="/About.html"
            class="mt-4 lg:inline-block lg:mt-0 hover:text-white mr-4 text-gray-600"
          >
            About</a>
          <a
            class="mt-4 lg:inline-block lg:mt-0 text-gray-600 hover:text-white mr-4"
            href="/feeds/all.atom.xml"
            >Atom</a
          >
          <a
            class="mt-4 lg:inline-block lg:mt-0 text-gray-600 hover:text-white mr-4"
            href="/feeds/all.rss.xml"
            >RSS</a
          >
        </div>
      </div>
    </nav>
    <div id="content" class="container max-w-screen-md px-8 py-4 mx-auto">
         <article>
  <header>
    <h2><a href="/blog/2013/05/proof-of-concept-eideticker-dashboard-for-firefoxos/">Proof of concept Eideticker dashboard for FirefoxOS</a></h2>
    <p class="index-date">May 6th, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p><em>[ For more information on the Eideticker software I&rsquo;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>I just put up a proof of concept Eideticker dashboard for FirefoxOS <a href="http://eideticker.wrla.ch/b2g">here</a>. Right now it has two days worth of data, manually sampled from an Unagi device running b2g18. Right now there are two tests: one the measures the &ldquo;speed&rdquo; of the contacts application scrolling, another that measures the amount of time it takes for the contacts application to be fully loaded.</p>

<p>For those not already familiar with it, Eideticker is a benchmarking suite which captures live video data coming from a device and analyzes it to determine performance. This lets us get data which is more representative of actual user experience (as opposed to an oft artificial benchmark). For example, Eideticker measures contacts startup as taking anywhere between 3.5 seconds and 4.5 seconds, versus than the 0.5 to 1 seconds that the <a href="https://datazilla.mozilla.org/b2g/?branch=master&amp;range=7&amp;test=cold_load_time&amp;app_list=contacts&amp;app=contacts&amp;gaia_rev=114bf216de0a19f7&amp;gecko_rev=9c0de2afd22a8476">existing datazilla benchmarks</a> show. What accounts for the difference? If you step through an eideticker-captured video, you can see that even though <em>something</em> appears very quickly, not all the contacts are displayed until the 3.5 second mark. There is a gap between an app being reported as &ldquo;loaded&rdquo; and it being fully available for use, which we had not been measuring until now.</p>

<p>At this point, I am most interested in hearing from FirefoxOS developers on new tests that would be interesting and useful to track performance of the system on an ongoing basis. I&rsquo;d obviously prefer to focus on things which have been difficult to measure accurately through other means. My setup is rather fiddly right now, but hopefully soon we can get some useful numbers going on an ongoing basis, as we <a href="http://eideticker.wrla.ch">do already</a> for Firefox for Android.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/04/further-meditative-practice/">Further meditative practice</a></h2>
    <p class="index-date">Apr 28th, 2013</p>
    <p><span class="tags"><a href="/tags/Buddhism.html">Buddhism</a>  <a href="/tags/Meditation.html">Meditation</a>  <a href="/tags/zen.html">zen</a></span></p>
  </header>

<center><a href="/files/2013/04/biodome.jpg"><img src="/files/2013/04/biodome-768x1024.jpg" alt="biodome" width="426" height="568" class="alignnone size-large wp-image-905" srcset="/files/2013/04/biodome-225x300.jpg 225w, /files/2013/04/biodome-768x1024.jpg 768w, /files/2013/04/biodome.jpg 1024w" sizes="(max-width: 426px) 100vw, 426px" /></a></center>

<p>Okay, remember <a href="http://wrla.ch/blog/2013/03/a-visit-to-the-montreal-zen-center/">last time</a> when I said I was going to continue my &ldquo;sham of a human existence&rdquo; and not commit to a Zen practice? Well, I came back to the idea sooner than I thought: the experience was just too compelling for me not to do some further exploration. In some strange coincidence, Hacker News had a <a href="https://news.ycombinator.com/item?id=5432713">great thread on meditation</a> just after I wrote my last blog entry, where a few people recommended a book called <a href="http://www.urbandharma.org/udharma4/mpe.html">Mindfulness in Plain English</a>. I figured doing meditation at home didn&rsquo;t involve any kind of huge commitment (don&rsquo;t like it? just stop!), so I decided to order it online and give it a try.</p>

<p>Mindfulness in Plain English is really fascinating stuff. It describes how to do a type of Vipassana (insight) meditation, which is practiced with a great deal of ritual in places like Thailand, India, and Sri Lanka. The book however, strips out most of the ritual and just gives you a set of techniques that is quite accessible for a (presumably) western audience. From what I can gather though, it seems like the goal of Vipassana is quite similar to that of Zen (enlightenment; release from attachment and dualism), though the methods and rituals around it are quite different (e.g. there are no koans). Perhaps it&rsquo;s akin to the difference between GIMP and Photoshop: as those two programs are both aimed at the manipulation of images, both Vipassana and Zen are aimed at the manipulation of the mind. There are differences in the script of how to do so, but the overarching purpose is the same.</p>

<p>Regardless, the portion of the C method that the book describes is almost exactly that which I tried at the Zen workshop: sit still and pay attention to your breathing. There&rsquo;s a few minor distinctions in terms of the suggested posture (the book recommends either sitting cross legged or in a lotus position vs. the kneeling posture I learnt at the workshop) and the focal point (Mindfulness recommends the tip of the nostrils). But essentially it&rsquo;s the same stuff. Focus on the breath &#8212; counting it if necessary, rince, repeat.</p>

<p>As I mentioned before, this is actually <em>really hard</em> to do properly for being simple in concept. The mind keeps wandering and wandering on all sorts of tangents: plans, daydreams, even thoughts about the meditation itself. Where I found Mindfulness in Plain English helpful was in the advice it gave for dealing with this &ldquo;monkey mind&rdquo; phenomenon. The subject is dealt with throughout the book (with two chapters on it and nothing else), but all the advice boils down to &ldquo;treat it as part of the meditation&rdquo;. Don&rsquo;t try to avoid it, just treat it as something to be aware of in the same way as breathing. Then once you have acknowledged it, move the attention back to the breath.</p>

<p>Mindfulness, as far as I can gather, is simply non-judgemental awareness of what we are doing (and what we are supposed to be doing). Every time a distraction is noticed, felt, and understood, you&rsquo;ve just experienced some approximation of the end goal of the meditation. Like it is with other things (an exercise regimen, learning to play a musical instrument), every small victory should push you further and the path to where you want to go. With enough practice, it might just become part of your day-to-day experience.</p>

<p>Or so I&rsquo;m told by the book. Up to now, I haven&rsquo;t enjoyed any longlasting effects from meditation aside from (possibly?) a bit more mental clarity in my day-to-day tasks. But I&rsquo;ve found the practice to be extremely interesting both from the point of view of understanding my own thought, as well as being rather relaxing in and of itself. So while I&rsquo;m curious as to what comes next, I am happy enough with things as they are in the present. I&rsquo;m planning to continue to meditate (20&ndash;30 minutes a day, 6 days a week), but also delve a bit deeper into the details and history of Zen and Vipasanna. More updates as appropriate.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/04/actual-useful-firefoxos-eideticker-results-at-last/">Actual useful FirefoxOS Eideticker results at last</a></h2>
    <p class="index-date">Apr 22nd, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p>Another update on getting <a href="http://wrla.ch/blog/2013/02/eideticker-for-firefoxos/">Eideticker working with FirefoxOS</a>. Once again this is sort of high-level, looking forward to writing something more in-depth soon now that we have the basics working.</p>

<p>I finally got the last kinks out of the rig I was using to capture live video from FirefoxOS phones using the Point Grey devices last week. In order to make things reasonable I had to write some custom code to isolate the actual device screen from the rest of capture and a few other things. The setup looks interesting (reminds me a bit of something out of the War of the Worlds):</p>

<p><a href="/files/2013/04/eideticker-pointgrey-mounted.jpg"><img src="/files/2013/04/eideticker-pointgrey-mounted.jpg" alt="eideticker-pointgrey-mounted" width="512" height="683" class="alignnone size-full wp-image-894" srcset="/files/2013/04/eideticker-pointgrey-mounted-224x300.jpg 224w, /files/2013/04/eideticker-pointgrey-mounted.jpg 512w" sizes="(max-width: 512px) 100vw, 512px" /></a></p>

<p>Here&rsquo;s some example video of a test I wrote up to measure the performance of contacts scrolling performance (measured at a very respectable 44 frames per second, in case you wondering):</p>

<video src="/files/eideticker/contacts-scrolling-pointgrey.webm" controls="controls"></video>

<p>Surprisingly enough, I didn&rsquo;t wind up having to write up any code to compensate for a noisy image. Of course there&rsquo;s a certain amount of variance in every frame depending on how much light is hitting the camera sensor at any particular moment, but apparently not enough to interfere with getting useful results in the tests I&rsquo;ve been running.</p>

<p>Likely next step: Create some kind of chassis for mounting both the camera and device on a permanent basis (instead of an adhoc one on my desk) so we can start running these sorts of tests on a daily basis, much like we currently do with Android on the <a href="http://eideticker.wrla.ch">Eideticker Dashboard</a>.</p>

<p>As an aside, I&rsquo;ve been really impressed with both the <a href="https://wiki.mozilla.org/Auto-tools/Projects/Marionette">Marionette</a> framework and the gaiatests python module that was written up for FirefoxOS. Writing the above test took just 5 minutes &#8212; and <a href="https://github.com/mozilla/eideticker/blob/master/src/tests/b2g/appscrolling/scroll.py">the code</a> is quite straightforward. Quite the pleasant change from my various efforts in Android automation.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/04/the-need-for-a-modern-open-source-email-client-and-geary-s-fundraiser/">The need for a modern open source email client and Geary&rsquo;s fundraiser</a></h2>
    <p class="index-date">Apr 19th, 2013</p>
    <p><span class="tags"><a href="/tags/email.html">email</a>  <a href="/tags/Free-Software.html">Free Software</a>  <a href="/tags/GNOME.html">GNOME</a></span></p>
  </header>

<div class="figure"><img src="http://www.yorba.org/images/igg/geary-2.png" alt="" />
 <p class="caption"></p></div>

<p>One of my frustrations with the Linux desktop is the lack of an email client that&rsquo;s in the same league as GMail or Apple&rsquo;s mail.app. <a href="https://www.mozilla.org/EN/thunderbird">Thunderbird</a> is ok as far as it goes (I use it for my day-to-day Mozilla correspondence) but I miss having a decent conversation view of email (yes, I tried the <a href="https://addons.mozilla.org/en-us/thunderbird/addon/gmail-conversation-view/">conversation view extension</a> &#8212; while impressive in some ways, it ultimately didn&rsquo;t work particularly well for me) and the search functionality is rather slow and cumbersome. I&rsquo;d like to be optimistic about these problems being fixed at some point but after nearly 2 years of using the product without much visible improvement my expectation of that happening is rather low.</p>

<p>The <a href="http://yorba.org">Yorba</a> non-profit recently started a <a href="http://www.indiegogo.com/projects/geary-a-beautiful-modern-open-source-email-client">fundraiser</a> to work on the next edition of Geary, an email client which I hope will fill the niche that I&rsquo;m talking about. It&rsquo;s pretty rough around the edges still, but even at this early stage the conversation view is beautiful and more or less exactly what I want. The example of Shotwell (their photo management application) suggests that they know a thing or two about creating robust and useable software, not a common thing in this day and age. In any case, their pitch was compelling enough for me to donate a few dollars to the cause. If you care about having a great email experience that is completely under your control (and not that of an advertising or product company with their own agenda), then maybe you could too?</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/03/a-visit-to-the-montreal-zen-center/">A visit to the Montreal Zen Center</a></h2>
    <p class="index-date">Mar 24th, 2013</p>
    <p><span class="tags"><a href="/tags/Buddhism.html">Buddhism</a>  <a href="/tags/zen.html">zen</a></span></p>
  </header>

<center><a href="/files/2013/03/zencenter.jpg"><img src="/files/2013/03/zencenter.jpg" alt="The Road to the Montreal Zen Center" width="640" height="853" class="alignnone size-full wp-image-871" srcset="/files/2013/03/zencenter-225x300.jpg 225w, /files/2013/03/zencenter.jpg 640w" sizes="(max-width: 640px) 100vw, 640px" /></a></center>

<p>So for a bit of a departure from the usual technical content, a personal anecdote. I went to the Montreal Zen Center today for a <a href="http://www.zenmontreal.ca/en/center/workshops.htm">workshop</a>, which was a most illuminating experience. I&rsquo;d been pretty fascinated with the idea of zen for a while (see this <a href="http://wlach.livejournal.com/8637.html">post of mine from 2006</a>, for example) but was pretty stuck on how to put it into practice (aside from being sure it was something you had <em>to live</em>). So, this was a step in that direction. After having gone to it, I wouldn&rsquo;t say I&rsquo;ve figured anything out (in fact I&rsquo;m more confused than ever), but I would say one thing with conviction: <em>this is the way to learn more</em>.</p>

<p>It was pretty simple stuff: exactly how they describe on the web page I linked to. A short verbal introduction on some of the ideas of zen, then a tea break, then instruction on how to begin practising meditation, another tea break (this time with biscuits), then actually practising meditation, then question &#38; answer about the meditation. It doesn&rsquo;t really sound like much, and it wasn&rsquo;t. But nonetheless I can&rsquo;t stop thinking about the experience.</p>

<p>As far as I can gather, the &ldquo;revelation&rdquo; offered by Zen Buddhism is simple: our existence as separate, unique beings is an illusion of the mind. This illusion makes us suffer. However, it is possible with practice to overcome this illusion and realize your true nature as being one with the world. I&rsquo;m probably butchering it a little bit by writing about it in this way, to a certain extent that&rsquo;s me, but in another way it&rsquo;s rather unavoidable since in a way the concepts are beyond words (since words imply a dualism). Regardless, the important thing isn&rsquo;t to grasp zen intellectually, but to come to a natural understanding through the practice of meditation (aka &ldquo;the practice&rdquo;).</p>

<p>And on that note, the meditation is austere and almost certainly less than you&rsquo;d expect. There is no prayer and very little ritual. Just a very minimal breath counting exercise conducted in a seated posture for 20 minutes, followed by a short walking exercise that lasts 5 minutes, then repeating the breath counting exercise for another 20 minutes. For its utter simplicity, I found it incredibly difficult. I imagine like anything with weeks, months, years of practice it (and the variations of it that experienced practitioners use where they meditate on <a href="http://en.wikipedia.org/wiki/K%C5%8Dan">koans</a>) it would become easier.</p>

<p>I&rsquo;m still giving thought on whether I want to take the next steps with them and begin a regular meditation practice. It sounds like really hard work (self meditation practice 6 days a week by yourself, plus regular visits to the zen center), which brings up the question: why do you want to do this? There&rsquo;s a weird contradiction between realizing that you as a self don&rsquo;t really exist and committing yourself radically to this kind of practice. The only thing I can call it would be a &ldquo;leap of faith&rdquo;. My current thinking is that I&rsquo;m not quite ready for that right now, but maybe in a while. For now I think I&rsquo;m pretty happy going to yoga a few times a week and living my sham of a human existence. ðŸ˜‰</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/03/eideticker-limitations-in-cross-browser-performance-testing/">Eideticker: Limitations in cross-browser performance testing</a></h2>
    <p class="index-date">Mar 20th, 2013</p>
    <p><span class="tags"><a href="/tags/Android.html">Android</a>  <a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p>Last summer I <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">wrote a bit</a> about using <a href="https://wiki.mozilla.org/Project_Eideticker">Eideticker</a> to measure the relative performance of Firefox for Android versus other browsers (Chrome, stock, etc.). At the time I was pretty optimistic about Eideticker&rsquo;s usefulness as a truly &ldquo;objective&rdquo; measure of user experience that would give us a more accurate view of how we compared against the competition than traditional benchmarking suites (which more often than not, measure things that a user will never see normally when browsing the web). Since then, there&rsquo;s been some things that I&rsquo;ve discovered, as well as some developments in terms of the &ldquo;state of the art&rdquo; in mobile browsing that have caused me to reconsider that view &#8212; while I haven&rsquo;t given up entirely on this concept (and I&rsquo;m still very much convinced of eideticker&rsquo;s utility as an internal benchmarking tool), there&rsquo;s definitely some limitations in terms of what we can do that I&rsquo;m not sure how to overcome.</p>

<p>Essentially, there are currently three different types of Eideticker performance tests:</p>

<ul>
 <li>Animation tests: Measure the smoothness of an animation by comparing frames and seeing how many are different. Currently the only example of this is the <a href="http://eideticker.wrla.ch/#/samsung-gn/clock/fps">canvas &ldquo;clock&rdquo; test</a>, but many others are possible.</li>
 <li>Startup tests: Measure the amount of time it takes from when the application is launched to when the browser is fully running/available. There are currently two variants of this test in the dashboard, both measure the amount of time taken to fully render Firefox&rsquo;s home screen (the only difference between the two is whether the browser profile is fully initialized). The <a href="http://eideticker.wrla.ch/#/samsung-gn/startup-abouthome-dirty/timetostableframe">dirty profile</a> benchmark probably most closely resembles what a user would usually experience.</li>
 <li>Scrolling tests: Measure the amount of undrawn areas when the user is panning a website. Most of the current eideticker tests are of this kind. A good example of this is the <a href="http://eideticker.wrla.ch/#/samsung-gn/taskjs/fps">taskjs benchmark</a>.</li></ul>

<p>In this blog post, I&rsquo;m going to focus on startup and scrolling tests. Animation tests are interesting, but they are also generally the sorts of tests that are easiest to measure in synthetic ways (e.g. by putting a frame counter in your javascript code) and have thus far not been a huge focus for Eideticker development.</p>

<p>As it turns out, it&rsquo;s unfortunately been rather difficult to create truly objective tests which measure the difference between browsers in these two categories. I&rsquo;ll go over them in order.</p>

<p><strong>Startup tests</strong></p>

<p>There are essentially two types of startup tests: one where you measure the amount of time to get to the browser&rsquo;s home screen when you explicitly launch the app (e.g. by pressing the Firefox icon in the app chooser), another where you load a web page in a browser from another app (e.g. by clicking on a link in the Twitter application).</p>

<p>The first is actually fairly easy to test across browsers, although we are not currently. There&rsquo;s not really a good reason for that, it was just an oversight, so I filed <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=852744">bug 852744</a> to add something like this.</p>

<p>The second case (startup to the browser&rsquo;s homescreen) is a bit more difficult. The problem here is that, in a nutshell, an apples to apples comparison is very difficult if not impossible simply because different browsers do different things when the user presses the application icon. Here&rsquo;s what we see with Firefox:</p>

<p><img src="/files/eideticker/firefox-startup.png" style="width:25%;" /></p>

<p>And here&rsquo;s what we see with Chrome:</p>

<p><img src="/files/eideticker/chrome-startup.png" style="width:25%;" /></p>

<p>And here&rsquo;s what we see with the stock browser:</p>

<p><img src="/files/eideticker/stock-startup.png" style="width:25%;" /></p>

<p>As you can see Chrome and the stock browser are totally different: they try to &ldquo;restore&rdquo; the browser back to its state from the last time (in Chrome&rsquo;s case, I was last visiting taskjs.org, in Stock&rsquo;s case, I was just on the homepage).</p>

<p>Personally I prefer Firefox&rsquo;s behaviour (generally I want to browse somewhere new when I press the icon on my phone), but that&rsquo;s really beside the point. It&rsquo;s possible to hack around what chrome is doing by restoring the profile between sessions to some sort of clean &ldquo;new tab&rdquo; state, but at that point you&rsquo;re not really reproducing a realistic user scenario. Sure, we can draw a comparison, but how valid is it really? It seems to me that the comparison is mostly only useful in a very broad &ldquo;how quickly does the user see something useful&rdquo; sense.</p>

<p><strong>Panning tests</strong></p>

<p>I had quite a bit of hope for these initially. They seemed like a place where Eideticker could do something that conventional benchmarking suites couldn&rsquo;t, as things like panning a web page are not presently possible to do in JavaScript. The main measure I tried to compare against was something called &ldquo;checkerboarding&rdquo;, which essentially represents the amount of time that the user waits for the page to redraw when panning around.</p>

<p>At the time that I wrote these tests, most browsers displayed regions that were not yet drawn while panning using the page background. We figured that it would thus be possible to detect regions of the page which were not yet drawn by looking for the background color while initiating a panning action. I thus hacked up existing web pages to have a magenta background, then wrote some image analysis code to detect regions that were that color (under the assumption that magenta is only rarely seen in webpages). It worked pretty well.</p>

<p>The world&rsquo;s moved on a bit since I wrote that: modern browsers like Chrome and Firefox use something like progressive drawing to display a lower resolution &ldquo;tile&rdquo; where possible in this case, so the user at least sees something resembling the actual page while panning on a slower device. To see what I mean, try visiting a slow-to-render site like taskjs.org and try panning down quickly. You should see something like this (click to expand):</p>

<p><a href="/files/eideticker/firefox-partialy-drawn.png"><img src="/files/eideticker/firefox-partialy-drawn.png" style="width:50%;" /></a></p>

<p>Unfortunately, while this is certainly a better user experience, it is not so easy to detect and measure. For Firefox, we&rsquo;ve disabled this behaviour so that we see the old checkerboard pattern. This is useful for our internal measurements (we can see both if our drawing code as well as our heuristics about when to draw are getting better or worse over time) but it only works for us.</p>

<p>If anyone has any suggestions on what to do here, let me know as I&rsquo;m a bit stuck. There are other metrics we could still compare against (i.e. how smooth is the panning animation aka frames per second?) but these aren&rsquo;t nearly as interesting.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/03/documentation-for-mozdevice/">Documentation for mozdevice</a></h2>
    <p class="index-date">Mar 11th, 2013</p>
    <p><span class="tags"><a href="/tags/Android.html">Android</a>  <a href="/tags/ateam.html">ateam</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p>Just wanted to give a quick heads up that as part of the ateam&rsquo;s ongoing effort to improve the documentation of our automated testing infrastructure, we now have <a href="https://mozbase.readthedocs.org/en/latest/mozdevice.html">online documentation</a> for mozdevice, the python library we use for interacting with Android- and FirefoxOS-based devices in automated testing.</p>

<p>Mozdevice is used in pretty much every one of our testing frameworks that has mobile support, including mochitest, reftest, <a href="https://wiki.mozilla.org/Buildbot/Talos">talos</a>, <a href="https://github.com/mozilla/autophone">autophone</a>, and <a href="https://wiki.mozilla.org/Project_Eideticker">eideticker</a>. Additionally, mozdevice is used by release engineering to clean up, monitor, and otherwise manage 
 <strike>our hundred-odd</strike> the 1200*** tegra and panda development boards that we use in <a href="http://tbpl.mozilla.org">tbpl</a>. See <a href="https://hg.mozilla.org/build/tools/file/tip/sut_tools">sut_tools</a> (old, buildbot-based, what we currently use) and <a href="https://github.com/mozilla/mozpool">mozpool</a> (the new and shiny future).</p>

<ul>
 <li>Thanks to Dustin Mitchell for the correction.</li></ul> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/03/follow-up-on-finding-a-camera-for-eideticker/">Follow up on &ldquo;Finding a Camera for Eideticker&rdquo;</a></h2>
    <p class="index-date">Mar 8th, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p>Quick update on my <a href="http://wrla.ch/blog/2013/02/finding-a-camera-for-eideticker/">last post</a> about finding some kind of camera suitable for use in automated performance testing of fennec and b2g with eideticker. Shortly after I wrote that, I found out about a company called <a href="http://ptgrey.com">Point Grey Research</a> which manufactures custom web cameras intended for exactly the sorts of things we&rsquo;re doing. Initial results with the <a href="http://ww2.ptgrey.com/USB3/Flea3">Flea3 camera</a> I ordered from them are quite promising:</p>

<video width="400px" src="/files/eideticker/pointgrey-taskjs.webm" controls="controls"></video>

<p>(the actual capture is even higher quality than that would suggest some detail is lost in the conversion to webm)</p>

<p>There seems to be some sort of issue with the white balance in that capture which is causing a flashing effect (I suspect this just involves flipping some kind of software setting: still trying to grok their SDK), and we&rsquo;ll need to create some sort of enclosure for the setup so ambient light doesn&rsquo;t interfere with the capture but overall I&rsquo;m pretty optimistic about this baby. 60 frames per second, very high resolution (1280x960), no issues with HDMI (since it&rsquo;s just a USB camera), relatively inexpensive.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/02/finding-a-camera-for-eideticker/">Finding a camera for Eideticker</a></h2>
    <p class="index-date">Feb 19th, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p><em>[ For more information on the Eideticker software I&rsquo;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>Ok, so as I mentioned <a href="http://wrla.ch/blog/2013/02/eideticker-for-firefoxos/">last time</a> I&rsquo;ve been looking into making Eideticker work for devices without native HDMI output by capturing their output with some kind of camera. So far I&rsquo;ve tried four different DSLRs for this task, which have all been inadequate for different reasons. I was originally just going to write an email about this to a few concerned parties, but then figured I may as well structure it into a blog post. Maybe someone will find it useful (or better yet, have some ideas.)</p>

<p><strong>Elmo MO&ndash;1</strong></p>

<p>This is the device I mentioned last time. Easy to set up, plays nicely with the Decklink capture card we&rsquo;re using for Eideticker. It seemed almost perfect, except for that:</p>

<ol>
 <li>The image quality is <em>really</em> bad (beaten even by $200 standard digital camera). Tons of noise, picture quality really bad. Not *necessarily* a deal breaker, but it still sucks.</li>
 <li>More importantly, there seems to be no way of turning off the auto white balance adjustment. This makes automated image analysis impossible if the picture changes, as is highlighted in this video:  
  <video width="400px" src="/files/eideticker/elmo-white-balance-problem.webm" controls="controls"></video></li></ol>

<p><strong>Canon Rebel T4i</strong></p>

<p>This is the first camera that was recommended to me at the camera shop I&rsquo;ve been going to. It does have an HDMI output signal, but it&rsquo;s not &ldquo;clean&rdquo;. This <a href="http://www.hireacamera.com/blog/index.asp?post=canon-eos-650d--hdmi-explained">blog post</a> explains the details better than I could. Next.</p>

<p><strong>Nikon D600</strong></p>

<p>Supposedly does native clean 720p output, but unfortunately the <a href="http://vimeo.com/49952287">output is in a &ldquo;box&rdquo;</a> so isn&rsquo;t recognized by the Decklink cards that we&rsquo;re using (which insist on a full 1280&#215;720 HDMI signal to work). Next.</p>

<p><strong>Nikon D800</strong></p>

<p>It is possible to configure this one to not put a box around the output, so the Decklink card does recognize it. Except that the camera shuts off the HDMI signal whenever the input parameters change on the card or the signal input is turned on, which essentially makes it useless for Eideticker (this happens every time we start the Eideticker harness). Quite a shame, as the HDMI signal is quite nice otherwise.</p>

<p>&#8212;</p>

<p>To be clear, with the exception of the Elmo all the devices above seem like fine cameras, and should more than do for manual captures of B2G or Android phones (which is something we probably want to do anyway). But for Eideticker, we need something that works in automation, and none of the above fit the bill. I guess I could explore using a &ldquo;real&rdquo; video camera as opposed to a DSLR acting like one, though I suspect I might run into some of the same sorts of issues depending on how the HDMI output of those devices behaves.</p>

<p>Part of me wonders whether a custom solution wouldn&rsquo;t work better. How complicated could it be to construct your own digital camera anyway? ðŸ˜‰ Hook up a fancy camera sensor to a <a href="http://pandaboard.org">pandaboard</a>, get it to output through the HDMI port, and then we&rsquo;re set? Or better yet, maybe just get a fancy webcam like the <a href="http://en.wikipedia.org/wiki/PlayStation_Eye">Playstation Eye</a> and hook it up directly to a computer? That would eliminate the need for our expensive video capture card setup altogether.</p> 
  <hr/>
</article>
<article>
  <header>
    <h2><a href="/blog/2013/02/eideticker-for-firefoxos/">Eideticker for FirefoxOS</a></h2>
    <p class="index-date">Feb 1st, 2013</p>
    <p><span class="tags"><a href="/tags/Eideticker.html">Eideticker</a>  <a href="/tags/FirefoxOS.html">FirefoxOS</a>  <a href="/tags/Mozilla.html">Mozilla</a></span></p>
  </header>

<p><em>[ For more information on the Eideticker software I&rsquo;m referring to, see <a href="http://wrla.ch/blog/2012/06/mobile-firefox-measuring-how-a-browser-feels/">this entry</a> ]</em></p>

<p>Here&rsquo;s a long overdue update on where we&rsquo;re at with Eideticker for FirefoxOS. While we&rsquo;ve had a good amount of success getting <a href="http://eideticker.wrla.ch">useful, actionable data</a> out of Eideticker for Android, so far we haven&rsquo;t been able to replicate that success for FirefoxOS. This is not for lack of trying: first, <a href="http://nakubu.com/">Malini Das</a> and then me have been working at it since summer 2012.</p>

<p>When it comes right down to it, instrumenting Eideticker for B2G is just a whole lot more complex. On Android, we could take the operating system (including support for all the things we needed, like HDMI capture) as a given. The only tricky part was instrumenting the capture so the right things happened at the right moment. With FirefoxOS, we need to run these tests on entire builds of a whole operating system which was constantly changing. Not nearly as simple. That said, I&rsquo;m starting to see light at the end of the tunnel.</p>

<p><strong>Platforms</strong></p>

<p>We initially selected the <a href="http://pandaboard.org">pandaboard</a> as the main device to use for eideticker testing, for two reasons. First, it&rsquo;s the same hardware platform we&rsquo;re targeting for other b2g testing in tbpl (mochitest, reftest, etc.), and is the platform we&rsquo;re using for running Gaia UI tests. Second, unlike every other device that we&rsquo;re prototyping FirefoxOS on (to my knowledge), it has HDMI-out capability, so we can directly interface it with the Eideticker video capture setup.</p>

<p>However, the panda also has some serious shortcomings. First, it&rsquo;s obviously not a platform we&rsquo;re shipping, so the performance we&rsquo;re seeing from it is subject to different factors that we might not see with a phone actually shipped to users. For the same reason, we&rsquo;ve had many problems getting B2G running reliably on it, as it&rsquo;s not something most developers have been hacking on a day to day basis. Thanks to the heroic efforts of Thomas Zimmerman, we&rsquo;ve mostly got things working ok now, but it was a fairly long road to get here (several months last fall).</p>

<p>More recently, we became aware of something called an <a href="http://www.elmousa.com/">Elmo</a> which might let us combine
 <br />the best of both worlds. An elmo is really just a tiny mounted video camera with a bunch of outputs, and is I understand most commonly used to project documents in a classroom/presentation setting. However, it seems to do a great job of capturing mobile phones in action as well.</p>

<video width="400px" src="/files/eideticker/startup-test-elmo.webm" controls="controls"></video>

<p>The nice thing about using an external camera for the video capture part of eideticker is that we are no longer limited to devices with HDMI out &#8212; we can run the standard set of automated tests on ANYTHING. We&rsquo;ve already used this to some success in getting some videos of FirefoxOS startup times versus Android on the Unagi (a development phone that we&rsquo;re using internally) for manual analysis. Automating this process may be trickier because of the fact that the video capture is no longer &ldquo;perfect&rdquo;, but we may be able to work around that (more discussion about this later).</p>

<p><strong>FirefoxOS web page tests</strong></p>

<p>These are the same tests we run on Android. They should give us an idea of roughly where our performance when browsing / panning web sites like CNN. So far, I&rsquo;ve only run these tests on the Pandaboard and they are INCREDIBLY slow (like 1&ndash;3 frames per second when scrolling). So much so that I have to think there is something broken about our hardware acceleration on this platform.</p>

<p><strong>FirefoxOS application tests</strong></p>

<p>These are some new tests written in a framework that allows you to script arbitrary interactions in FirefoxOS, like launching applications or opening the task switcher.</p>

<p>I&rsquo;m pretty happy with this. It seems to work well. The only problems I&rsquo;m seeing with this is with the platform we&rsquo;re running these tests on. With the pandaboard, applications look weird (since the screen resolution doesn&rsquo;t remotely resemble the 320&#215;480 resolution on our current devices) and performance is abysmal. Take, for example, this capture of application switching performance, which operates only at roughly 3&ndash;4 fps:</p>

<video width="400px" src="/files/eideticker/b2g-appswitching-video.webm" controls="controls"></video>

<p><strong>So what now?</strong></p>

<p>I&rsquo;m not 100% sure yet (partly it will depend on what others say as well as my own investigation), but I have a feeling that capturing video of real devices running FirefoxOS using the Elmo is the way forward. First, the hardware and driver situation will be much more representative of what we&rsquo;ll actually be shipping to users. Second, we can flash new builds of FirefoxOS onto them automatically, unlike the pandaboards where you currently either need to manually flash and reset (a time consuming and error prone process) or set up an instance of <a href="https://github.com/djmitche/mozpool">mozpool</a> (which I understand is quite complicated).</p>

<p>The main use case I see with eideticker-on-panda would be where we wanted to run a suite of tests on checkin (in tbpl-like fashion) and we&rsquo;d need to scale to many devices. While cool, this sounds like an expensive project (both in terms of time and hardware) and I think we&rsquo;d do better with getting something slightly smaller-scale running first.</p>

<p>So, the real question is whether or not the capture produced by the Elmo is amenable to the same analysis that we do on the raw HDMI output. At the very least, some of eideticker&rsquo;s image analysis code will have to be adapted to handle a much &ldquo;noisier&rdquo; capture. As opposed to capturing the raw HDMI signal, we now have to deal with the real world and its irritating fluctuations in ambient light levels and all that the rest. I have no doubt it is *possible* to compensate for this (after all this is what the human eye/brain does all the time), but the question is how much work it will be. Can&rsquo;t speak for anyone else at Mozilla, but I&rsquo;m not sure if I really have the time to start a Ph.D-level research project in computational vision. ðŸ˜‰ I&rsquo;m optimistic that won&rsquo;t be necessary, but we&rsquo;ll just have to wait and see.</p> 
  <hr/>
</article>
<footer>
 <ul class="pagination">
  <li class="page-item"><a class="page-link" href="/index-10.html">
    <quote>&larr;</quote></a></li>
  <li class="page-item"><a class="page-link" href="/index.html">1</a></li>
  <li class="page-item"><a class="page-link" href="/index-2.html">2</a></li>
  <li class="page-item"><a class="page-link" href="/index-3.html">3</a></li>
  <li class="page-item"><a class="page-link" href="/index-4.html">4</a></li>
  <li class="page-item"><a class="page-link" href="/index-5.html">5</a></li>
  <li class="page-item"><a class="page-link" href="/index-6.html">6</a></li>
  <li class="page-item"><a class="page-link" href="/index-7.html">7</a></li>
  <li class="page-item"><a class="page-link" href="/index-8.html">8</a></li>
  <li class="page-item"><a class="page-link" href="/index-9.html">9</a></li>
  <li class="page-item"><a class="page-link" href="/index-10.html">10</a></li>
  <li class="page-item active"><a class="page-link" href="/index-11.html">11</a></li>
  <li class="page-item"><a class="page-link" href="/index-12.html">12</a></li>
  <li class="page-item"><a class="page-link" href="/index-13.html">13</a></li>
  <li class="page-item"><a class="page-link" href="/index-14.html">14</a></li>
  <li class="page-item"><a class="page-link" href="/index-15.html">15</a></li>
  <li class="page-item"><a class="page-link" href="/index-16.html">16</a></li>
  <li class="page-item"><a class="page-link" href="/index-17.html">17</a></li>
  <li class="page-item"><a class="page-link" href="/index-12.html">
    <quote>&rarr;</quote></a></li></ul></footer>
    </div>
    <footer class="container max-w-screen-md px-8 py-4 mx-auto less-important">
      <p>Comments / thoughts? Feel free to send an email to wlach on protonmail.com,
        or toot <a rel="me" href="https://mastodon.social/@wlach">@wlach@mastodon.social</a>.
      </p>
      <p>
        Site generated by
        <a href="https://github.com/greghendershott/frog">Frog</a>.
        Post content is licensed under a
        <a rel="license" href="http://creativecommons.org/licenses/by/4.0/"
          >Creative Commons Attribution 4.0 Unported License</a
        >.
      </p>
    </footer>
  </body>
</html>